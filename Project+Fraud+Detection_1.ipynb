{"cells":[{"cell_type":"markdown","source":["# Fraud Detection"],"metadata":{"collapsed":true}},{"cell_type":"markdown","source":["## Import Spark SQL and Spark ML Libraries"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.classification import LogisticRegression"],"metadata":{"collapsed":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["## Load Source Data"],"metadata":{}},{"cell_type":"markdown","source":["The data for the project is about mobile money transactions based on a sample of real transactions extracted from one month of financial logs from a mobile money service implemented in an African country. The original logs were provided by a multinational company, who is the provider of the mobile financial service which is currently running in more than 14 countries all around the world.\n\nThis synthetic dataset is scaled down 1/4 of the original dataset and it is created just for Kaggle.\nThe data comes in a .csv format."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\n# @hidden_cell\n# This function is used to setup the access of Spark to your Object Storage. The definition contains your credentials.\n# You might want to remove those credentials before you share your notebook.\ndef set_hadoop_config_with_credentials_f63cbb38899d47179c49ed4a7cf03ccf(name):\n    \"\"\"This function sets the Hadoop configuration so it is possible to\n    access data from Bluemix Object Storage using Spark\"\"\"\n\n    prefix = 'fs.swift.service.' + name\n    hconf = sc._jsc.hadoopConfiguration()\n    hconf.set(prefix + '.auth.url', 'https://identity.open.softlayer.com'+'/v3/auth/tokens')\n    hconf.set(prefix + '.auth.endpoint.prefix', 'endpoints')\n    hconf.set(prefix + '.tenant', '265dd6d8a99a4549a24ac9574846808d')\n    hconf.set(prefix + '.username', '886a93bbc2564a539f02a62ed61e1a61')\n    hconf.set(prefix + '.password', 'h8bjj]J[1DME7LnC')\n    hconf.setInt(prefix + '.http.port', 8080)\n    hconf.set(prefix + '.region', 'dallas')\n    hconf.setBoolean(prefix + '.public', False)\n\n# you can choose any name\nname = 'keystone'\nset_hadoop_config_with_credentials_f63cbb38899d47179c49ed4a7cf03ccf(name)\n\nspark = SparkSession.builder.getOrCreate()\n\n#df = spark.read\\\n  #.format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  #.option('header', 'true')\\\n  #.option(\"inferSchema\", \"true\")\\\n  #.load('swift://ITBSProjectFraudDetection.' + name + '/frauddetectionsmall.csv')\ndf = sqlContext.sql(\"SELECT * FROM frauddetection\")\ndf.take(5)\ndf.dtypes\n"],"metadata":{"collapsed":false},"outputs":[],"execution_count":6},{"cell_type":"code","source":["\n'''df = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .option(\"inferSchema\", \"true\")\\\n  .load('swift://ITBSProjectFraudDetection.' + name + '/frauddetectionsmall.csv')\ndf.take(5)'''\n"],"metadata":{"collapsed":false},"outputs":[],"execution_count":7},{"cell_type":"code","source":["'''%matplotlib inline\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfraud = df.toPandas()\nf, ax = plt.subplots(1, 1, figsize=(8, 8))\nfraud.type.value_counts().plot(kind='bar', title=\"Transaction type\", ax=ax, figsize=(8,8))\nplt.show()\nplt.figure(0)\ncond = (fraud['isFraud'] >= 1)\ntaf = fraud[cond].type.value_counts().plot(kind='bar',  title=\"Fraud transactions grouped by type\")\nplt.show(taf)\nplt.figure(1)\ncond2 = (fraud['isFraud'] < 1)\ntaf2 = fraud[cond2].type.value_counts().plot(kind='bar',  title=\"No fraud transactions grouped by type\")\nplt.show(taf2)\n#fraud['type'] = fraud['type'].apply(convert)\n#fraud1 = normalize(fraud)\nplt.figure(2)\nmedianprops = dict(linestyle='-', linewidth=2, color='blue')\nbx1 = fraud[cond2].boxplot(column=['oldbalanceDest', 'newbalanceDest'], by='isFraud', medianprops=medianprops)\nbx2 = fraud[cond2].boxplot(column=['oldbalanceOrg', 'newbalanceOrig'], by='isFraud', medianprops=medianprops)\nbx3 = fraud[cond2].boxplot(column=['amount'], by='isFraud', medianprops=medianprops)\n#bx4 = fraud[cond].boxplot(column=['type'], by='isFraud', medianprops=medianprops)\nplt.show(bx1)\nplt.show(bx2)\nplt.show(bx3)\n#plt.figure(3)\n#hist1 = fraud[cond2].plot.hist(by='isFraud', stacked=True, bins=20)'''"],"metadata":{"collapsed":false},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["## Scatter Plots\nNext, we want to interpret trends in our data using scatter plots."],"metadata":{}},{"cell_type":"code","source":["'''plt.figure(4)\nsc1 = fraud.plot.scatter(x='oldbalanceDest', y='newbalanceDest')\nsc2 = fraud.plot.scatter(x='oldbalanceOrg', y='newbalanceOrig')\nsc1 = fraud.plot.scatter(x='oldbalanceDest', y='oldbalanceOrg')\nsc2 = fraud.plot.scatter(x='oldbalanceOrg', y='newbalanceDest')\nsc3 = fraud.plot.scatter(x='amount', y='isFraud')\nsc4 = fraud.plot.scatter(x='oldbalanceDest', y='isFraud')\nsc5 = fraud.plot.scatter(x='newbalanceDest', y='isFraud')\nsc6 = fraud.plot.scatter(x='oldbalanceOrg', y='isFraud')\nsc7 = fraud.plot.scatter(x='newbalanceOrig', y='isFraud')\nplt.show(sc1)\nplt.show(sc2)\nplt.show(sc3)\nplt.show(sc4)\nplt.show(sc5)\nplt.show(sc6)\nplt.show(sc7)'''"],"metadata":{"collapsed":false},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["## Select the columns\nIn the next step, we will drop the columns that are useless for our model."],"metadata":{}},{"cell_type":"code","source":["df2 = df.select(\"type\", \"amount\", \"oldbalanceOrg\", \"newbalanceOrig\", \"oldbalanceDest\", \"newbalanceDest\", (col(\"isFraud\").cast(\"Int\").alias(\"label\")))\ndf2.take(5)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["## Split the data\nIn the next step we split the data in a train and test set."],"metadata":{}},{"cell_type":"code","source":["splits = df2.randomSplit([0.7, 0.3])\ntrain = splits[0]\ntest = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\ntrain_rows = train.count()\ntest_rows = test.count()\nprint \"Training Rows:\", train_rows, \" Testing Rows:\", test_rows\ntrain.show(5)\ntest.show(5)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["## Define a pipeline and train the model\nWe need to prepare the features."],"metadata":{}},{"cell_type":"code","source":["strIdx = StringIndexer(inputCol = \"type\", outputCol = \"typeCat\")\nlabelIdx = StringIndexer(inputCol = \"label\", outputCol = \"idxLabel\")\ncatVect = VectorAssembler(inputCols = [\"typeCat\"], outputCol=\"catFeatures\")\ncatIdx = VectorIndexer(inputCol = catVect.getOutputCol(), outputCol = \"idxCatFeatures\")\nnumVect = VectorAssembler(inputCols = [\"amount\", \"oldbalanceOrg\", \"newbalanceOrig\", \"oldbalanceDest\", \"newbalanceDest\"], outputCol=\"numFeatures\")\nminMax = MinMaxScaler(inputCol = numVect.getOutputCol(), outputCol=\"normFeatures\")\nfeatVect = VectorAssembler(inputCols=[\"idxCatFeatures\", \"normFeatures\"], outputCol=\"features\")\n\ncl = []\npipeline = []\n\ncl.insert(0, DecisionTreeClassifier(labelCol=\"idxLabel\", featuresCol=\"features\"))\ncl.insert(1, RandomForestClassifier(labelCol=\"idxLabel\", featuresCol=\"features\"))\ncl.insert(2, LogisticRegression(labelCol=\"idxLabel\", featuresCol=\"features\"))\n\n# Pipeline process the series of transformation above, which is 7 transformation\nfor i in range(3):\n    pipeline.insert(i, Pipeline(stages=[strIdx, labelIdx, catVect, catIdx, numVect, minMax, featVect, cl[i]]))\nprint \"Pipeline complete!\""],"metadata":{"collapsed":false},"outputs":[],"execution_count":16},{"cell_type":"code","source":["model = []\n\nparamGrid = (ParamGridBuilder().addGrid(cl[0].impurity, (\"gini\", \"entropy\")).addGrid(cl[0].maxDepth, [5, 10, 20]).addGrid(cl[0].maxBins, [5, 10, 20]).build())\ncv = TrainValidationSplit(estimator=pipeline[0], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)\nmodel.insert(0, cv.fit(train))\nprint \"Model 1 completed\"\n\nparamGrid2 = (ParamGridBuilder().addGrid(cl[1].impurity, (\"gini\", \"entropy\")).addGrid(cl[1].maxDepth, [5, 10, 20]).addGrid(cl[1].maxBins, [5, 10, 20]).build())\ncv2 = TrainValidationSplit(estimator=pipeline[1], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid2, trainRatio=0.8)\nmodel.insert(1, cv2.fit(train))\nprint \"Model 2 completed\"\n\nparamGrid3 = (ParamGridBuilder().addGrid(cl[2].regParam, [0.01, 0.5, 2.0]).addGrid(cl[2].threshold, [0.30, 0.35, 0.5]).addGrid(cl[2].maxIter, [1, 5]).addGrid(cl[2].elasticNetParam, [0.0, 0.5, 1]).build())\ncv3 = TrainValidationSplit(estimator=pipeline[2], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)\nmodel.insert(2, cv3.fit(train))\nprint \"Model 3 completed\""],"metadata":{"collapsed":false},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["## Test the model\nWe transform the test dataframe to generate label predictions."],"metadata":{}},{"cell_type":"code","source":["'''predictions = model.transform(test)\npredicted = predictions.select(\"features\", \"prediction\", \"probability\", \"trueLabel\")\npredicted.show(100, truncate=False)\nfor row in predicted.collect():\n    print row'''\nprediction = [] \npredicted = []\nfor i in range(3):\n  prediction.insert(i, model[i].transform(test))\n  predicted.insert(i, prediction[i].select(\"features\", \"prediction\", \"probability\", \"trueLabel\"))\n  predicted[i].show(30)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["## Evaluation\nIn the next step we evaluate the model"],"metadata":{}},{"cell_type":"code","source":["#from pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nevaluator = BinaryClassificationEvaluator(\n    labelCol=\"trueLabel\", rawPredictionCol=\"prediction\")\nfor i in range(3):\n\n\n\n\n    #evaluator = MulticlassClassificationEvaluator(\n    #labelCol=\"trueLabel\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n    areUPR = evaluator.evaluate(predicted[i], {evaluator.metricName: \"areaUnderPR\"})\n    areUROC = evaluator.evaluate(predicted[i], {evaluator.metricName: \"areaUnderROC\"})\n    print(\"AreaUnderPR = %g \" % (areUPR))\n    print(\"AreaUnderROC = %g \" % (areUROC))\n\n    tp = float(predicted[i].filter(\"prediction == 1.0 AND truelabel == 1\").count())\n    fp = float(predicted[i].filter(\"prediction == 1.0 AND truelabel == 0\").count())\n    tn = float(predicted[i].filter(\"prediction == 0.0 AND truelabel == 0\").count())\n    fn = float(predicted[i].filter(\"prediction == 0.0 AND truelabel == 1\").count())\n\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n    print(\"Precision = %g \" % (precision))\n    print(\"Recall = %g \" % (recall))\n\n    metrics = sqlContext.createDataFrame([\n    (\"TP\", tp),\n    (\"FP\", fp),\n    (\"TN\", tn),\n    (\"FN\", fn),\n    (\"Precision\", tp / (tp + fp)),\n    (\"Recall\", tp / (tp + fn))],[\"metric\", \"value\"])\n    metrics.show()\n"],"metadata":{"collapsed":false},"outputs":[],"execution_count":21}],"metadata":{"celltoolbar":"Raw Cell Format","kernelspec":{"display_name":"Python 2 with Spark 2.1","language":"python","name":"python2-spark21"},"name":"Project+Fraud+Detection (1)","notebookId":192786901858517},"nbformat":4,"nbformat_minor":0}
